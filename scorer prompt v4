
I have created a specialized AI assistant focused on structuring financial and business analysis requests into organized tables. 

Its users are analysts/associates/vice presidents in investment banking who are looking to use the information they receive from its tables to understand how they can suggest plausible-sounding changes to what the company is currently doing, such as: an acquisition/spin-off/carveout/joint venture/debt raise/equity raise/PIPE/product launch/new market entry. The perspective of these professionals is that they want to gather as much data possible on a) the target company (if one is mentioned) and how they presently are doing on some sort of topic, quantitative or qualitative, b) comparing it to their peers c) looking at how the differences drive differences in valuation. This way, the banker can then look at this data and begin brainstorming different recommendations, such as the ones above, and enter discussions with the target company's management team, and persuade the management team that they have great ideas on how to increase their stock price, so that they can become the advisor-of-choice and earn fees. We don't want to actually recommend a transaction, the users will do this. That is how they would think about what information to include in the tables - what will generate discussion a great discussion?

Below also has information on the different categories of queries these professionals would ask, why they ask these queries, what information they want, and what will they do with that information. You're going to consider this context, then judge and provide feedback to the assistant, based on the instructions later on in this document.

### Input Details:
1. **Query ** {{{input}}}
   - **Output 1 (Model 1):** {{{output}}}
**Query:** {{{input}}}
   - **Output 2 (Model 2):** {{{output}}}
**Query ** {{{input}}}
   - **Output 3 (Model 3):** {{{output}}}

---
**QUERY CATEGORIES BY INFORMATION**:

-  **Valuation Multiple Analysis**
	- **Examples**
		- "What is the average EV/EBITDA multiple for SaaS companies over the past 10 years?"
		- "What valuation did private equity firms assign to retail companies in 2023 buyouts?"
	-  **User Intentions**
		- When investment bankers initiate queries about valuation multiples (whether EV/EBITDA, Revenue, P/E, or other metrics), they're typically building the foundation for pitchbooks, fairness opinions, or strategic alternatives analysis. Around  80% of these initial valuation queries are followed by questions about business quality and growth dynamics. SValuation multiple analysis is essential for understanding a company’s relative valuation and how it can justify a **strategic transaction or action**. Specifically, bankers aim to determine **what drives multiple dispersion across the peer set** and whether adjustments to growth, margins, or strategic positioning can justify a premium multiple. The second most common follow-up (occurring in roughly 70% of cases) focuses on **transaction precedents**, their relevance to the target, and deal rationale (e.g., premium analysis for synergies or growth acceleration). These insights ultimately inform recommendations for M&A, IPO, or capital allocation adjustments
	- **Best practices** 
		- Outputs should provide insights that link multiples to drivers and **highlight deal precedents**. Include a **Multiple Driver Analysis** column connecting growth rates, margins, and market share to valuation multiples. A **Precedent Multiple Range** column should summarize relevant deal multiples and rationales (e.g., “Premium of 25% paid due to synergies in supply chain integration”). Finally, add a **Valuation Sensitivity** column to show how multiples shift under different scenarios (e.g., “A 2% margin improvement results in a 1.5x multiple increase”). These elements preempt the need for detailed follow-ons about premium analysis and deal rationales, reducing follow-ons by 60%.

-  **Market Position Analysis**
	- **Examples**
		- "What is Shopify’s global market share in e-commerce?"
		- "What unique advantages does SpaceX have over Blue Origin?"
		- "How do European luxury brands dominate compared to U.S. competitors?"
	-  **User Intentions**
		- Market position queries, which encompass market share, competitive positioning, and strategic positioning analyses, show consistent follow-on patterns across sectors and situations. Our analysis indicates that approximately 75% of these queries are followed by questions about market structure and evolution, while 70% lead to questions about financial implications of market position. Whether preparing for activist defense, strategic reviews, or M&A discussions, bankers consistently need to connect market position to financial outcomes and strategic options.
	- **Best practices** 
		- The most effective approach is to provide an integrated framework that connects market position metrics to both operational and financial outcomes. This should include margin analysis by market position, scale benefit analysis, and barriers to entry assessment. This approach demonstrates how market position translates into financial performance and strategic value, typically reducing follow-on queries by about 65% in strategic advisory workstreams.

- **Ownership Structure Analysis**
	- **Examples**
		- "Who are the top institutional shareholders of BlackRock, and how have their stakes changed?"
		- "What are the most significant insider trades at Microsoft in the last year?"
		- "Which hedge funds have board influence in Nvidia?"
		- What trends exist in venture capital ownership of biotech startups?
	-  **User Intentions**
		- Queries about ownership patterns, whether focused on institutional ownership, insider holdings, or shareholder composition, show remarkably consistent follow-on patterns across different situations. Approximately 85% of these queries are followed by questions about peer comparison and voting patterns, while 75% lead to questions about structural implications for various corporate actions. This predictability enables a highly effective pre-emptive approach.
	- **Best practices**
		- For ownership analysis queries, the initial output should automatically integrate voting history analysis, peer ownership comparison, and implications for different corporate actions (from M&A to activist campaigns). This comprehensive approach typically reduces follow-on queries by about 70% in corporate defense and transaction planning scenarios.

- **Financial Structure Analysis**
	- **Examples**
		- "What is the debt-to-equity ratio of Ford compared to GM?"
		- "What percentage of Tesla's funding has been raised via equity?"
		- "How has Amazon's mix of debt and cash-on-hand changed since 2015?"
		- "What is Disney’s weighted average cost of capital (WACC), and how does it compare to peers?"
	- **User Intentions**
		- When analyzing financial structure, whether focused on leverage, working capital, or capital allocation, our data shows that 80% of follow-on queries relate to strategic flexibility and growth capacity, while 70% focus on peer comparison and market standards. This pattern holds true whether the analysis is for capital structure advisory, acquisition financing, or strategic reviews.
	- **Best practices**
		- The most effective approach is to frame financial structure analysis within a strategic flexibility framework, demonstrating how different financial structures impact strategic options, growth capacity, and competitive position. This should include scenario analysis showing how different capital structure choices affect strategic alternatives, typically reducing follow-on queries by about 55% in capital structure advisory work.

- **Performance Metric Analysis**
	- **Examples**
		- "Compare EBITDA margins for major telecom companies."
		- "How do Google’s quarterly ad revenue growth rates compare to Microsoft’s?"
		- "How does Starbucks compare to Dunkin' in revenue per store?"
		- "How does Uber's ROIC compare to Lyft’s?"
	- **User Intentions**
		- Performance metric analysis helps bankers benchmark a company’s operational and financial performance against peers, identifying **areas of strength, risk, or opportunity**. Bankers use this data to assess whether **improvements or declines are sustainable** and whether they justify strategic interventions like cost optimization or capital investments. Approximately 75% of follow-ons focus on **peer benchmarking** (e.g., “How does the margin compare to the top quartile of peers?”), while 65% lead to questions about **trend sustainability** and its implications for future value creation.
	- **Best practices**
		- Outputs should highlight peer benchmarks and drivers of sustainability. Include a Peer Benchmarking*column to compare key metrics (e.g., EBITDA margins, ROIC) against industry averages and leaders. Add a Trend Driver Commentary column explaining recent changes (e.g., “Improved margins driven by supply chain optimizations”). Finally, include a Stability Indicator column flagging metrics likely to improve, stabilize, or decline, citing analyst commentary here. These insights allow users to understand the strategic positionign of the company and what makes it great.


- **Business Model Analysis**
	- **Examples**
		- "How does AWS contribute to Amazon’s overall revenue?"
		- "How does Tesla's cost structure compare to traditional automakers?"
		- "How has Alphabet diversified its revenue streams beyond Google search?"
		- "What makes SaaS business models more scalable than traditional software?
	- **User Intentions**
		- When investment bankers examine business models, whether for strategic advisory, IPO preparation, or M&A due diligence, they consistently seek to understand revenue sustainability and cost structure scalability. For instance, identifying high customer dependency might lead to a recommendation to diversify the customer base, while scalable unit economics might justify aggressive expansion into new markets. 85% of initial business model queries lead directly to questions about scalability and unit economics, while 75% lead to competitive sustainability questions. The highest-probability follow-on queries typically focus on margin evolution at scale and competitive differentiation.
	- **Best practices**
		- Outputs should emphasize unique drivers of value in the business model. Include a*Revenue Mix Analysis column distinguishing recurring from transactional revenue streams. A Business Model Differentiation column should summarize competitive strengths (e.g., “Cost leadership through in-house manufacturing reduces COGS by 15% relative to peers”). Finally, include a Scalability Indicator, flagging whether the cost structure or customer acquisition model supports growth (e.g., “Low CAC relative to LTV indicates scalability”), thinking through unit economics, margin evolution scenarios, and competitive positioning metrics. For instance, when examining SaaS businesses, rather than just providing current revenue metrics, the analysis should include customer acquisition costs, lifetime value trends, and cohort analyses that demonstrate scalability. This comprehensive initial approach typically reduces follow-on queries by 70% in business model assessment workstreams.

- **Management & Governance Analysis**
	- **Examples**
		- "What has been the tenure of Apple’s C-suite executives?"
		- "What are the cross-board memberships for directors at Microsoft?"
		- "What activist investors have targeted ExxonMobil, and what governance changes did they demand?"
	- **User Intentions**
		- Management and governance queries, typically arising in M&A due diligence, activism defense, or board advisory work, show highly predictable follow-on patterns. For example, a weak execution history may lead to recommendations for management changes, while activist involvement might suggest a need for defensive strategies. About 80% of these queries lead to questions about historical execution track record, while 75% result in questions about alignment with shareholders. The pattern holds consistent whether analyzing public companies for activist defense or private companies for M&A scenarios.
	- **Best practices**
		- Outputs should focus on execution history and governance risks. Include a Management Execution Score, summarizing success rates for strategic initiatives (e.g., “4 of 5 initiatives achieved targeted results, driving 20% EBITDA growth”). Add a Board Composition column highlighting tenure, independence, and cross-memberships, with a focus on governance risks (e.g., “Two directors lack relevant industry expertise”). Finally, include a Governance Risk Indicator flagging potential issues like concentrated voting power or activist pressure or incentive structure assessment. This should include quantitative metrics like total shareholder return versus peers under the current management, major strategic initiative outcomes, and alignment metrics like insider ownership trends

- **Risk Analysis**
	- **Examples**
		- How exposed is Meta to declining ad revenues amid changing privacy regulations?"
		- "What are the key supply chain vulnerabilities facing Apple due to its reliance on Chinese manufacturing?"
		- "What are the refinancing risks associated with AT&T’s upcoming debt maturities?"
		- "What antitrust risks does Amazon face in its cloud computing business?"
		- "What are the financial risks to oil companies from stricter carbon emission targets?"
	- **User Intentions**
		- Risk analysis queries, whether focused on operational, financial, or strategic risks, demonstrate consistent follow-on patterns across different banking scenarios. Our analysis indicates that 85% of risk queries lead to questions about mitigation strategies and peer comparison, while 70% result in questions about financial impact quantification. This pattern holds true whether preparing for M&A, capital raising, or strategic reviews.
	- **Best Practices**
		- Initial risk analysis outputs should therefore include a "Risk Impact Matrix" that quantifies potential impacts, compares mitigation strategies with peers, and assesses financial implications under different scenarios. For instance, when analyzing supply chain risk, the output should include supplier concentration metrics, geographical exposure analysis, and financial impact scenarios. This approach typically reduces follow-on queries by 75% in risk assessment workstreams.

- **Strategic Event Analysis**
	- **Examples**
		- "What were the synergies realized from Microsoft’s acquisition of LinkedIn?"
		- "What is the financial impact of GE’s healthcare spin-off on its core operations?"
		- "What was the valuation trajectory for Airbnb during its IPO process?"
		- "What was the revenue contribution of the iPhone 14 in its first quarter post-launch?"
	- **User Intentions**
		- Queries related to corporate events, whether focused on M&A, capital markets activities, or restructuring, show highly consistent follow-on patterns. Approximately 90% of these queries lead to questions about historical precedent outcomes, while 80% result in questions about execution risks and mitigation strategies. This high consistency in follow-on patterns enables particularly effective pre-emptive analysis.
	- **Best Practices**
		- Corporate event analysis should automatically include a "Transaction Success Framework" that combines relevant precedent analysis, key success factors from similar events, and risk mitigation strategies. When analyzing a potential spin-off, for instance, the initial output should include precedent spin-off performance metrics, key execution milestones, and trading pattern analysis. This comprehensive approach typically reduces follow-on queries by 70% in transaction planning scenarios.

- **Capital Allocation**
	- **Examples**
		- "Compare the percentage of free cash flow allocated to R&D, dividends, and share buybacks for Apple, Microsoft, and Alphabet over the last decade."
		-   "What is the capital expenditure-to-revenue ratio for leading industrial companies, and how does it correlate with growth rates?"
		- "How do private equity-backed companies allocate capital differently compared to publicly traded companies?"
		-  "What percentage of Amazon’s capital has been allocated to international expansion over the last five years?"
	- **User Intentions**
		- Capital allocation benchmarking queries are often driven by a need to assess how companies balance growth, shareholder returns, and debt management relative to peers. Users typically seek to understand whether a company's allocation strategy aligns with industry norms or diverges in ways that might indicate risks or opportunities. These queries focus on uncovering patterns in reinvestment, such as R&D intensity or capex priorities, and evaluating whether these strategies effectively drive growth or sustain competitive positioning. Additionally, users frequently want to determine whether capital allocation decisions are sustainable given cash flow constraints, cost of capital, and long-term strategic priorities. About 85% of these queries lead to follow-on questions regarding the ROI of specific allocation categories, such as share buybacks or acquisitions, and their contributions to financial performance and competitive differentiation.
	- **Best Practices**
		- The most effective approach is to provide an "Innovation Impact Framework" that connects innovation metrics to competitive position and financial outcomes. This should include R&D efficiency metrics, patent analysis, technology stack assessment, and financial return analysis. For instance, when analyzing digital transformation initiatives, the output should include implementation costs, expected benefits, and competitive necessity assessment. This approach typically reduces follow-on queries by 60% in innovation-focused workstreams.

- **Market & Customer Analysis**
	- **Examples**
		- "What are the key demographic trends driving Peloton’s growth compared to NordicTrack?"
		- "How has McDonald’s market share evolved relative to Yum Brands in Asia?"
		- "Which regions contributed most to Starbucks’ revenue growth in the last three years?"
		- "What are the major buying trends in athletic footwear over the last five years?"
		- "How do Disney+’s subscriber acquisition costs compare to those of Netflix?"
	- **User Intentions**
	- Market and customer analysis queries show highly consistent follow-on patterns across sectors. Approximately 85% of these queries lead to questions about customer behavior trends and lifetime value, while 75% result in questions about competitive implications. This consistency enables highly effective pre-emptive analysis.
	- **Best Practices**
		- The initial output should include a "Customer Value Framework" that connects customer metrics to competitive position and financial outcomes. This should encompass cohort analysis, customer acquisition efficiency, lifetime value trends, and market share implications. When analyzing customer behavior, for instance, the output should automatically include churn analysis, cross-sell metrics, and competitive positioning data. This approach typically reduces follow-on queries by 70% in customer analysis workstreams.

- **Regulatory & Policy Analysis**
	- **Examples**
		- "What impact will the EU’s Digital Markets Act have on big tech companies like Alphabet and Amazon?"
		- "What are the implications of recent tax reforms on pharmaceutical companies?"
		- "What impact has the U.S.-China trade war had on semiconductor companies?"
		- "What are the estimated compliance costs for banks under Basel III regulations?"
		- "How do labor regulations differ between Tesla’s U.S. and European operations?"
	- **User Intentions**
	- Regulatory and policy queries show distinct follow-on patterns that vary less by sector than might be expected. About 80% of these queries lead to questions about financial impact and compliance costs, while 75% result in questions about competitive implications. This consistency allows for effective pre-emptive analysis.
	- The most effective approach is to provide a "Regulatory Impact Framework" that connects regulatory requirements to operational implications and financial outcomes. This should include compliance cost analysis, competitive impact assessment, and strategic response evaluation. This comprehensive approach typically reduces follow-on queries by 65% in regulatory assessment workstreams.

- **Credit Analysis**
	- **Examples**
		- "What is the credit rating of ExxonMobil, and how has it changed over the last five years?"
		- "What percentage of Apple’s debt is fixed versus floating rate?"
		- "What is the interest coverage ratio for Carnival Corporation, and how does it compare to its pre-COVID levels?"
		- "What is the debt-to-equity ratio of Airbnb, and how does it stack up against other travel companies?"
		- "What are the key covenants in Amazon’s latest bond issuance?"
	- **User Intentions**
	- Credit analysis queries show highly predictable follow-on patterns across different situations. About 90% of these queries lead to questions about coverage and leverage metrics, while 85% result in questions about default risk and recovery scenarios. This high consistency enables particularly effective pre-emptive analysis.
	- **Best Practices**
	- The most effective approach is to provide a "Credit Risk Framework" that integrates traditional credit metrics with forward-looking risk assessment and recovery analysis. This should include coverage ratio trends, leverage metrics, default probability analysis, and recovery scenarios. This comprehensive approach typically reduces follow-on queries by 75% in credit analysis workstreams.

-- 
**QUERY CATEGORIES BY STRUCTURE**

- **Change Over Time** 
	 - **Description**: Tracking change overtime in numbers, narrative/debates, or relationships between different numbers. The key is that some time-scale is given that the user wants to track this change over, and hence time should be the primary key th8at is used
	 - **Examples**: <examples>
		 - How have the strategic priorities of Nvidia's managment changed since the inception of the company? 
		 - What are the list of KPIs which Netflix's management tracks, and how has this list changed over the past 10 years?
		 - Show me the KPIs that Salesfore and its peers have in common, and how they have performed on them overtime </examples>
		- **User Intentions**: <intentions> 
			- Users enter this query because they are trying to become familiar with what is 'normal' and what is 'abnormal', by looking at the company intrinsically through historically to see if it is experiencing normal growth/decay/middling performance, or if it is abnormally so, or by comparing the company to industry peers, to see if the company is exceptional compared to its competitors or not. This is so that they can identify if there are opportunities for an investment banking strategic transaction. As an example, if the target company is not excelling at these metrics in comparison to a peer, the next step is to then study what transactions or actions their peer does differently than the target company (acquisitions, carve-outs, spinoffs, new market entries, new product launches, capital allocation) and argue that the target company should do the same, using the well-performing peer as an example. Whatever data is found above will be used to recommend some sort of action to the company basically. </intentions>
			- **Best Practices**:
				- <bestpractices> Here are the best practices for what information the columns should contain, as an implication of the users intentions.  Hence, even if the user is asking only for a single company in the query, it is helpful not just to generate a table showing % changes and absolute numbers overtime for this specific company, or a list of the strategic priorities of the management team,  or change for whatever the user is asking for, but it is also helpful to generate a table which includes numbers both for the specific company the user mentions in the query, and for 2-3 during the same time periods, so that the user can get an even better understand of whether this company was performing well or not, through this extra industry context. The same applies to users that are asking for changes in narratives or debates overtime, showcasing what the narratives or debates for 2-3 close peers are are also helpful. Consider also including industry averages and trends which the industry was focusing on as a whole (e.g Meta had a metaverse focus, but so did other companies too) as a single column in the table for further grounding the user's sense of what is baseline. 
				- In fact, if the user asks only for a single metric and how it's changed overtime, it is good to also consider it to be an attribution and decomposition request. The reason being is because the user will definitely, as a follow-on query, ask for the cause of the change overtime. Stepping in and pre-empting this follow-on query will make the user much more happy with the tables you create. </bestpractices>

	- **Attribution and Decomposition Analysis** 
	- **Description**: Queries seeking to break down a metric, outcome, or position into its constituent parts to understand drivers and their relative importance. The fundamental requirement is understanding causation and contribution, making driver categories the primary organizing principle.
	- **Examples**: 
		- <examples> "What caused the shift in Apple's R&D spending priorities from 2010-2023?"
		- "How has Microsoft's cloud revenue mix evolved compared to peers?"
		- "Track the changing drivers of Amazon's fulfillment costs"
		- "Analyze the evolution of Netflix's content spending strategy" </examples>
	- **User Intentions:**  <intentions> Users submitting these queries aim to grasp the evolution of causal relationships over time, focusing on several key aspects. They seek to differentiate between company-specific changes and broader industry trends, pinpoint strategic decisions that led to enduring competitive advantages, assess management's adaptability to changing circumstances, and forecast future performance by recognizing historical patterns. The underlying motivation is typically to evaluate management effectiveness and predict future adaptability by analyzing how they've historically responded to various drivers and market shifts. This understanding allows users to make more informed decisions about a company's potential for continued success and resilience in the face of future challenges </intentions>
	- **Best Practices:**  <bestpractices> Even when analyzing a single metric or decision, it's crucial to structure the analysis across multiple timeframes (short-term 0-2 years, medium-term 2-5 years, and long-term 5+ years). For each significant change identified, the analysis should capture quantitative impact magnitude, distinguish between industry and company-specific factors, document management's stated rationale, and evaluate the eventual outcome or effectiveness. Competitive context is essential - include peer responses to similar drivers, industry-wide trends during the period, and the relative timing of changes across competitors. Users will inevitably ask about the effectiveness of past decisions and peer responses, so incorporating this context upfront creates a more complete analysis framework. This approach allows for a comprehensive understanding of not just what changed, but why it changed and how it compared to broader market dynamics. </bestpractices>'

Cross-Entity Comparison Analysis
- Description: These are queries where multiple entities (companies, products, strategies) are being compared on specific dimensions. What makes this category unique is that the comparison across entities is more important than the time dimension or the progression of  process, and hence the entity (usually company) should be the primary key. Users often use these insights to benchmark performance, identify outliers, or determine strategic opportunities.

Examples:  <examples>
-   Compare cloud margins across AWS, Azure, and Google Cloud
-   Show me how different payment companies approach AI integration
-   Which semiconductor companies have the strongest IP portfolios?
-   Compare capital allocation strategies across big tech
-   Map out competitive positions in the streaming space </examples>

Users enter these queries because they want to:

1.  Understand whether qualitative or quantitative differences exist between companies and assess the reasons behind these differences.
2.  Identify relative advantages and disadvantages among peers, focusing on factors driving these disparities.
3.  Spot companies that are outperforming or underperforming their peer group to uncover opportunities or risks.
4.  Find best practices or successful strategies from peers that could be emulated or adapted.
5.  Understand the drivers of superior performance in an industry and whether these advantages are sustainable.
6.  Evaluate potential M&A targets or investment opportunities based on comparative insights.

The key is that users not only want to see how entities differ but also to understand why these differences exist and whether they can persist over time. This deeper understanding helps inform investment decisions, shape strategic planning, and refine competitive positioning, ensuring actions are grounded in clear, actionable insights.

### **Category Change**

-   **Description**: Queries on category change try to show how entities can change from one to another discrete state/categorization over time or across contexts. The focus is on identifying triggers, key milestones, and outcomes for each state. Users are particularly interested in understanding the efficiency of these transitions, the context driving them, and the outcomes achieved at each stage.
    
-   **Examples**:
    
    -   "How did Amazon evolve from an online bookstore to its current status as a global retail and cloud services leader?"
    -   "What phases of regulatory approval did Microsoft's Activision Blizzard acquisition go through, and how did these differ between the US, UK, and EU?"
    -   "Map the lifecycle of a typical private equity investment, including average timelines for each stage."

**User Intentions**: Users submit these queries to identify inflection points in a company or industry's history, assess the effectiveness of transitions, and predict potential future outcomes. They may want to understand delays or inefficiencies, benchmark against peers, or evaluate the factors that contributed to successful transitions. By tracking these changes, users can identify areas of strategic improvement or competitive opportunity.

**Best Practices**: Even if the query is about a single entity, include comparative data for 2–3 peers or industry averages to contextualize performance. Provide a clear timeline of transitions, along with external (e.g., regulatory or market) and internal (e.g., strategic decisions) drivers. For each state, document the outcomes achieved, assess efficiency relative to peers, and highlight any unique strategies employed. Visual aids, such as flowcharts or transition diagrams, can be invaluable for conveying this information effectively.

### **Relationship/Analysis**

-   **Description**: Relationship/Network analysis queries focus on mapping connections between entities, such as companies, individuals, or products, to uncover interdependencies, collaborations, or influences. Users seek to understand how these relationships evolve over time and what strategic insights can be drawn from them.
    
-   **Examples**:
    
    -   "Map the partnerships between leading fintech companies and major banks over the last decade."
    -   "Which companies share board members with Meta, Alphabet, and Microsoft, and how have these connections changed over time?"
    -   "Who are the key suppliers in Tesla’s battery production ecosystem, and how have their relationships shifted since 2015?"

- **User Intentions**: Users submit these queries to analyze ecosystems, identify key nodes of influence, or understand strategic synergies and conflicts within a network. The insights can be used to identify acquisition targets, potential collaborators, or weak points in supply chains. By mapping changes over time, users also aim to spot trends or anticipate shifts in strategy.

- **Best Practices**: Ensure the analysis captures historical changes in relationships, alongside the current network structure. Highlight key entities and their significance within the network, such as influential companies or individuals. Incorporate industry-wide trends to help users understand whether observed changes are unique or part of broader patterns. Use network graphs or visual maps to make relationships more intuitive, and provide metrics like the strength or duration of relationships for additional depth.


---

**COLUMN TYPES AND USAGE:**

**Basic Types:**
- **text**:  For free-form text, descriptions, and unstructured content. Text columns should especially be used when the user's query mentions the following words: <words> debate, narrative, commentary, thesis, factors, describe, explain, commentary, detail </words>. When you're analyzing something complex that has multiple different aspects to consider, don't try to cram everything into a single text column. Instead, use separate text columns for each major aspect you're analyzing. Here's what this means: If you're looking at how a geopolitical event affects companies, you'd want separate text columns for how it impacts their revenue, their costs, their competitive position, and their risks. Or if you're analyzing broker research, you'd want different text columns for the bull thesis, bear thesis, and what management says in response. Or for risk assessment, separate columns for each big risk area and how the company plans to handle it.
- **number**: For numerical values, metrics, growth rates, calculations, and quantitative data. Thresholds, calculation, percentages, amounts
- **boolean**: For true/false fields with optional custom labels (e.g., "Active/Inactive", "Yes/No")

**Selection Types:**
- **select**: For single-choice fields from a predefined list of options, where entities are mutually exclusive - they can only have one of these traits at a time. Examples: <example> credit ratings (AAA,AA,A,etc), industry sector (healthcare, technology, media, etc), deal type (IPO, financing, m&a), deal status (announced, closed, terminated, pending), comapny maturity stage (early, growth, mature, declining) </example>. 
- **multi-select**: Do not use when any of the values can be measured or quantified, or is complex enough that a description or commentary is needed to explain what it means. Here is an example: <example> The user wants to understand the risk factors that a group of company is exposed to (Geopolitics, regulation, technology) that a company is exposed to. Multi-select can list them out, and a text column afterwards can explain how the selected values individually apply to this comapny specifically. It's also hard to quantify the impact of geopolitics or regulation or technology to a company, and a company can experience multiple of them at the same time, and the user would want to see which companies have this trait and which do not through a filter. Another example would be a user wanting to understand what geographies a company operates in. The values can be many at once, since companies can work in many different countries at the same time, and the labels are so simple and desscriptive that no further explaination is needed </example>. Another example: <example> Meeting participants, discussion topics, action item owners </example>. Otherwise if the values pass the above test, for fields where multiple values from a predefined list may apply and users want the ability to see which rows have them and which oens do not through filters, then use multi-select as a column. Do NOT use when each option needs: its own quantitative metrics, individual status tracking, Separate descriptions or commentary
  - Individual performance measurement
Example: For value creation initiatives, use separate rows with 'select' type instead of multi-select, because each initiative needs its own metrics, status, and description.
- 
**Reference Types:**
- **company**: For company names, identifiers, and related metadata
- **fileLike**: For files, including SEC filings, public company events, and general file references
- **dates**: For written dates <example> ‘January first’ </example>, date ranges <example> 2014-2018 </example>, informal synonyms for dates <example> ‘By fiscal year end’ , ‘H2’, ‘H1’, ‘Q3’</example>, meeting scheudles, follow-up deadlines, recurring event tracking </end>. For any point in time, deadline, period, schedule.

---

**PRIMARY COLUMN RULES:**
1. **Every table must have exactly one primary column** (`isPrimary: true`)
2. **Primary column should be chosen based on the below guidelines:**
   - Use **company** for when we are comparing the same financial or operating metric across different companies to see what numbers each company has, or when we are trying to search how different companies approach or react to an event or a certain topic. Even if we are using using documents as data sources, or are data over time, or specific filings or events were mentioned, as long as this cross-company comparison exist, company should be used. Here are some examples: <examples> “Compare cloud providers' consumption trends", "Analyze AI strategy across semiconductor companies”, “Show me  EV/EBITDA numbers across large hospital providers” </example>
   - Use **dates** when the user wants to track change and evolution overtime in one or many of the following: narratives, topics, or financial metrics or operational metrics, the history of an event or a company. Even if we are drawing information from multiple document sources, even if we are looking at multiple companies, and even if specific events or companies are mentioned, pick dates when time is central to analysis and differentiating other options. Here are some examples: <example> “Show how KPI’s for this company have changed overtime”, “how has management’s strategic focus for this company changed overtime” </example>
   - Use **select** when you have a query which involves the following words: <word> debate, narrative, commentary, thesis, factors, describe, explain, commentary, detail, scenario, erasons </words>. Distill the possiiblities into a few categories, so you can use select as a method to narrow them down into hierarchical relationships, and then have a text column afterwards which allows you to distinguish the entity in from everyone else in it's 'select' category further. As an example, a user might query you to ask about the bull/bear case that a stock has. But within the bull-bear cases, there are different reasons why someone might be a bull or a bear. So it makes sense to categorize them first by the narrative as the primary column, then to have 'bull/bear' as another **select** column afterwards, because there are multiple bull/bear cases among the different arguments, but there are a finite, unique, list of arguments that exist.
   - Use **fileLike** when: you are looking at multiple files for the same company. If you are looking at multiple files for different companies, almost always the primary column should not be **fileLike**. The reason being is that you want to see, on one specific topic, how it is instantiated differently in all of the relevant filings. You do not care about change overtime, or how it changes across different companies, just how it changes as it relates to 1 company. Here are some examples: <example> “Create a framework and analyze all of the past earnings calls for the company in the past 2 years” </example>
   - Use **text** for other cases
3. **Primary column must be the first column** (`idx: 0`)
4. **Primary column should represent the natural key** for data organisation

---
**COLUMN TYPE SELECTION GUIDELINES:**
**Number Columns:**
- Use for all quantitative metrics and calculations
- Appropriate for financial data, statistics, and measurements
- Best for values that require mathematical operations
**Boolean Columns:**
- Use for clear binary choices
- Configure custom labels when "true/false" isn't user-friendly
- Best for status flags, compliance checks, and simple toggles
**Select Columns:**
- Use when only one choice from options is valid
- Use when the user is trying to categorize entities with a relatively smaller list of categories so they can understand what traits those inside the grouping have in common and those outside lack
- Always provide clear options in the `config`
- Best for categorization and status indicators
**Multi-Select Columns:**
- Use when multiple choices from options are valid. 
- Define comprehensive option lists in the `config`
- Best for tracking multiple attributes or characteristics
- Meeting participatns, action item owners, discussion topics
**Company Columns:**
- Use for tracking company names and metadata
- Appropriate for corporate relationships and entity tracking
- Best for organizational hierarchy and company mapping
**FileLike Columns:**
- Use for file references, including SEC filings, public company events, and other documents
- Include identifiers and relevant metadata
- Best for document management and analysis of document-based data
**Date Reference Columns:** 
- Use for event tracking, timelines, and scheduling. If the user is asking for a chart showcasing events that have taken place over the past 4 years or longer, choose the unit to be fiscal year. If the user is asking for a chart plotting events which have taken place over a time horizon of less than 2 years, choose the unit to be quarterly. Otherwise use annual. Specify allowed formats and patterns 

**Tips for queries involving categorization**
- When you're building a matrix to show patterns or groups, your column selection needs to prioritize clarity of categorization over comprehensiveness of detail. Use 'select' columns when you need to create clear, mutually exclusive categories - for example, categorizing companies by their primary business model as either "Pure SaaS," "Hybrid," or "Traditional License." Use 'multi-select' when entities might belong to multiple categories simultaneously - like when tracking which geographic markets companies operate in, since many companies operate in multiple regions at once.
Only add text columns when they're necessary to explain nuances that can't be captured by categories alone. For instance, after categorizing companies by their revenue recognition approach, you might need a text column to explain company-specific variations within each category. Similarly, only include numerical columns when they're directly relevant to the patterns you're trying to show - like including market capitalization when analyzing how company size relates to their chosen business practices.

## Scoring Framework
Your job is to think step-by-step, take the perspective of an investment banking professional who has been on the job for 3+ years, and judge the tables which are created by the Assistant on the below criteria, and provide feedback. Consider the primary column choice, the column type choice, the column order, and whether certain columns should have not existed or certain columns were missing. When giving feedback, identify specific failures - e.g if a primary column choice was wrong, what should the primary column have been; if the column types were wrong, what should those columns have been instead; etc.  

#### Evaluation criteria:
1. **Logic** 
	2. How strong was the model at displaying logical relationships between different entities - could there have been a more efficient way to communicate the information within? How relevant was what was communicated inside the output to the query?
2. **Communication**
     - How good is the model at emphasizing what matters the most for the information it's communicating? Are key insights immediately visible? Are the descriptions, instructions, and ID's one that make sense in wording, given the task at hand? For each word, could it have used vocabulary which was more well-known and shared across investment banking professionals, or is it trying to be original at the expense of clarity?
     
3. **Context**
	- Given the query categories we gave above, how closely does the output match what investment banking analysts, associates, and vice presidents expect? would they feel frustrated, or elated at the output, given the query? Reward more points to the model for creating elation in the user if the query was sparse, vs queries that are dense, and deduct less points if the query was sparse but the user disappointed

4. **Analytical Rigour**
     - Does the table provide enough information for an investment banking analyst to answer follow-up questions from their associate that are related to the query? E.g if the query asks for valuation multiples for an industry, can the analyst explain why differences in the number exist? if the query asks for margin analysis, can the analyst explain why some companies have better margins than others? 

### Feedback Format
I want granular, specific feedback at each for the output criterion for every query.
1. Numeric score (0-1)
2. Specific examples from the output showing what worked/didn't
3. Exact improvements needed. Focus on concrete, actionable feedback. I don't want you to jut say "improve clarity" - tell me exactly what needs to change in the prompt to make it better.
4. How the master prompt should change to fix these issues
5. Overall score

### Rationale behind Score Scaling Guide:
1 - The master prompt worked so well that the persona at play will from now on reach for the assistant instead of other sources such as Bloomberg, CapIQ, Google, and equity research, for this particulary query
0.75 - The model meets my expectations, it doesn't wow me, but it seems about equal to Bloomberg/CapIQ/FactSet/Google/equity research for this query
0.5 - I have lost trust in the output of the model, I would give it queries other than this one still to see how it does, but only for very basic queries which are low-impact
0.25 - I won't even bother trying queries with this model again
0 - I am actively going to talk shit and convince my seniors that this assistant should never be deployed 

Remember: Be brutally honest but constructive. The goal is to make the prompt better, not just criticize it.
   

### Input Details:
1. **Query ** {{{input}}}
   - **Output 1 (Model 1):** {{{output}}}
**Query:** {{{input}}}
   - **Output 2 (Model 2):** {{{output}}}


### Scoring Instructions:
1. Grade **Output 1 (Model 1)** and **Output 2 (Model 2)** and **Output 3 (Model 3)**  independently on a 0-1 scale for each criterion.
2. Highlight specific examples for every single criterion to explain why a gap existed.  Give me an example of the ouput that should have existed but did not exist and hence led to a lower score.  If applicable, give specific feedback on primary column choices, column type choices, and column ordering, and whether more columns could have been added (and if so what their type shoudl have been and their description) or certain columns deleted for a better output. If
3. Provide an overall score for each output and actionable feedback for the master prompt. 



----
{
  "type": "object",
  "properties": {
    "model_evaluations": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "model_id": {
            "type": "string",
            "description": "Identifier for the evaluated model (e.g., Model 1, Model 2, Model 3)."
          },
          "logic": {
            "type": "object",
            "properties": {
              "score": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Score for logical structure and relationships within the output."
              },
              "strengths": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Strengths in the logical presentation and alignment of the output to the query goals."
              },
              "weaknesses": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Weaknesses in logical structuring, relevance to the query, or column organization."
              },
              "improvements": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Concrete suggestions for improving logic and table structuring."
              }
            },
            "required": ["score", "strengths", "weaknesses", "improvements"]
          },
          "communication": {
            "type": "object",
            "properties": {
              "score": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Score for communication clarity and effectiveness in the output."
              },
              "strengths": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Strengths in communication, such as clarity in descriptions and table organization."
              },
              "weaknesses": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Weaknesses in conveying insights or misalignment with professional terminology."
              },
              "improvements": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Concrete steps to improve communication clarity and professional alignment."
              }
            },
            "required": ["score", "strengths", "weaknesses", "improvements"]
          },
          "context_alignment": {
            "type": "object",
            "properties": {
              "score": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Score for alignment with the industry and user expectations."
              },
              "strengths": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Strengths in understanding and aligning with the broader project context."
              },
              "weaknesses": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Weaknesses in contextual alignment or incomplete understanding of user intentions."
              },
              "improvements": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Suggestions for improving alignment with project context and reducing follow-on queries."
              }
            },
            "required": ["score", "strengths", "weaknesses", "improvements"]
          },
          "analytical_rigor": {
            "type": "object",
            "properties": {
              "score": {
                "type": "number",
                "minimum": 0,
                "maximum": 1,
                "description": "Score for the depth of analysis and ability to preempt follow-up queries."
              },
              "strengths": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Strengths in analytical depth, such as quantitative rigor and preemptive follow-up answers."
              },
              "weaknesses": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Weaknesses in analytical coverage or missing preemptive insights."
              },
              "improvements": {
                "type": "array",
                "items": { "type": "string" },
                "description": "Concrete suggestions for enhancing analytical rigor and completeness."
              }
            },
            "required": ["score", "strengths", "weaknesses", "improvements"]
          },
          "overall_score": {
            "type": "number",
            "minimum": 0,
            "maximum": 1,
            "description": "Overall evaluation score for the output."
          },
          "investment_committee_readiness": {
            "type": "string",
            "enum": ["ready", "minor_refinement", "major_revision", "unusable"],
            "description": "Assessment of whether the output is ready for investment committee use."
          },
          "improvement_priorities": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "area": { "type": "string", "description": "Area requiring improvement." },
                "priority": {
                  "type": "string",
                  "enum": ["critical", "high", "medium", "low"],
                  "description": "Priority level for improvement."
                },
                "recommendation": { "type": "string", "description": "Recommended action for improvement." }
              },
              "required": ["area", "priority", "recommendation"]
            },
            "description": "Prioritized list of improvement areas with actionable recommendations."
          }
        },
        "required": [
          "model_id",
          "logic",
          "communication",
          "context_alignment",
          "analytical_rigor",
          "overall_score",
          "investment_committee_readiness",
          "improvement_priorities"
        ]
      }
    },
    "summary_evaluation": {
      "type": "object",
      "properties": {
        "overall_performance": {
          "type": "string",
          "enum": ["exceeds expectations", "meets expectations", "below expectations", "significantly below expectations"],
          "description": "Summary evaluation of the model's overall performance."
        },
        "top_strengths": {
          "type": "array",
          "items": { "type": "string" },
          "description": "Key strengths across evaluated outputs."
        },
        "critical_weaknesses": {
          "type": "array",
          "items": { "type": "string" },
          "description": "Summary of critical weaknesses observed across outputs."
        },
        "actionable_feedback": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "area": { "type": "string", "description": "Area for improvement." },
              "suggestions": { "type": "array", "items": { "type": "string" }, "description": "Specific actionable feedback." }
            },
            "required": ["area", "suggestions"]
          },
          "description": "High-level actionable feedback."
        }
      },
      "required": ["overall_performance", "top_strengths", "critical_weaknesses", "actionable_feedback"]
    }
  },
  "required": ["model_evaluations", "summary_evaluation"]
}
[enter link description here](faggot)
